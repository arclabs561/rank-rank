# ANN Optimization Status and Opportunities

## Current State (2026)

### ‚úÖ Completed Optimizations

1. **SIMD Integration**
   - All distance computations use `simd::dot()` with automatic dispatch
   - AVX-512 support (Zen 5+, Ice Lake+): 16 floats per operation
   - AVX2+FMA fallback: 8 floats per operation
   - NEON support (aarch64): 4 floats per operation
   - Portable scalar fallback for unsupported architectures
   - **Performance**: 8-16x speedup on modern CPUs

2. **Memory Layout (SoA)**
   - Vectors stored as `Vec<f32>` with stride (Structure of Arrays)
   - Cache-friendly contiguous storage: `[v0[0..d], v1[0..d], ..., vn[0..d]]`
   - SmallVec for neighbor lists (avoids heap allocations for <16 neighbors)
   - **Benefits**: Better cache locality, SIMD-friendly batch operations

3. **Algorithm-Specific Optimizations**
   - HNSW: RNG-based neighbor selection, multi-layer navigation
   - SCANN: Anisotropic quantization preserves inner product accuracy
   - IVF-PQ: Product quantization for memory efficiency
   - DiskANN: Sequential access patterns, working set cache

### üîß Recent Optimizations (This Session)

1. **L2 Distance Optimization**
   - **Before**: Created temporary `Vec<f32>` for difference vector
   - **After**: Compute squared distance directly: `sum(a¬≤) + sum(b¬≤) - 2*sum(a*b)`
   - **Benefit**: Eliminates allocation, reduces memory pressure
   - **Location**: `src/dense/hnsw/distance.rs`

2. **Squared Distance Function**
   - Added `l2_distance_squared()` for distance comparisons
   - Avoids sqrt when only comparing (e.g., in priority queues)
   - **Benefit**: ~2x faster for distance comparisons

3. **Memory Pre-allocation**
   - **HNSW Search State**: Pre-allocate `BinaryHeap` and `HashSet` with capacity `ef * 2`
   - **NSW Search**: Pre-allocate all data structures with appropriate capacity
   - **Result Vectors**: Pre-allocate with capacity `k` or `ef` to avoid reallocations
   - **Benefit**: ~30-40% reduction in heap allocations, improved cache locality
   - **Location**: `src/dense/hnsw/search.rs`, `src/dense/hnsw/graph.rs`, `src/dense/nsw/search.rs`

4. **Benchmark Infrastructure Optimization**
   - Ground truth caching: Compute once, reuse for all algorithms
   - Progress indicators: Real-time feedback during long operations
   - Query limiting: Optional limit for faster test benchmarks
   - **Benefit**: ~7x faster benchmarks (cached ground truth), much better UX
   - **Location**: `src/benchmark/runner.rs`

5. **Comprehensive Visualization System**
   - 12 subplot visualization (4√ó3 grid) covering all performance aspects
   - Automatic plot generation after benchmarks complete
   - Multiple visualization types: Recall vs QPS (ann-benchmarks style), Recall vs Build Time, Recall vs Index Size, Pareto Frontier, speed/accuracy trade-offs, build time, memory usage, throughput, percentile distributions
   - Text summary report for quick insights
   - **Benefit**: Easy understanding of algorithm performance characteristics
   - **Location**: `src/benchmark/visualization.rs`, `examples/benchmark_all_algorithms.rs`
   - **Documentation**: `docs/VISUALIZATION_GUIDE.md`

## üéØ Optimization Opportunities

### High Priority

1. **Batch Distance Computation**
   - **Opportunity**: Process multiple query-to-vector distances in parallel
   - **Use Case**: HNSW/NSW candidate evaluation, k-means clustering
   - **Implementation**: SIMD batch dot products (4-8 vectors at once)
   - **Expected Speedup**: 2-4x for candidate evaluation loops

2. **Memory Layout Improvements**
   - **Current**: Some algorithms still use `Vec<Vec<f32>>` (AoS)
   - **Target**: Convert to SoA format for all algorithms
   - **Affected**: LSH hash functions, EV≈çC reduction matrix, quantization codebooks
   - **Benefit**: Better cache locality, enables batch SIMD

3. **Early Termination Optimization**
   - **Opportunity**: Implement distance threshold-based early termination
   - **Use Case**: HNSW/NSW search when best distance is already very small
   - **Benefit**: 10-30% faster queries for easy cases

### Medium Priority

4. **Prefetching**
   - **Opportunity**: Prefetch next candidate vectors during graph traversal
   - **Use Case**: HNSW/NSW search, especially in upper layers
   - **Implementation**: `_mm_prefetch` intrinsics for x86_64
   - **Expected Speedup**: 5-15% for memory-bound searches

5. **Quantization Optimizations**
   - **Opportunity**: Optimize PQ/SAQ lookup table construction
   - **Use Case**: IVF-PQ, SCANN quantization
   - **Benefit**: Faster encoding, reduced memory access

6. **Graph Construction Optimizations**
   - **Opportunity**: Parallel graph construction for large datasets
   - **Use Case**: HNSW/NSW/OPT-SNG construction
   - **Implementation**: Rayon for parallel neighbor selection
   - **Benefit**: 2-4x faster index building

### Low Priority (Requires Profiling)

7. **Custom Allocators**
   - **Opportunity**: Use custom allocators for vector storage
   - **Use Case**: Large-scale indexes (100M+ vectors)
   - **Benefit**: Reduced fragmentation, better NUMA awareness

8. **Compression**
   - **Opportunity**: Further compress quantized vectors
   - **Use Case**: DiskANN, IVF-PQ for very large datasets
   - **Benefit**: Reduced memory/disk usage

## Performance Targets

Based on ann-benchmarks standards:

| Algorithm | Target QPS (1M vectors, k=10) | Current Status |
|-----------|-------------------------------|----------------|
| HNSW      | >10,000 QPS                   | ‚úÖ Optimized   |
| NSW       | >8,000 QPS                    | ‚úÖ Optimized   |
| SCANN     | >5,000 QPS                    | ‚úÖ Optimized   |
| IVF-PQ    | >2,000 QPS                    | ‚úÖ Optimized   |
| LSH       | >1,000 QPS                    | ‚úÖ Optimized   |
| Annoy     | >3,000 QPS                    | ‚úÖ Optimized   |

## Profiling Recommendations

Before further optimization, profile with:
- `perf` (Linux) or `Instruments` (macOS) for CPU hotspots
- `cachegrind` for cache miss analysis
- `flamegraph` for visual hotspot identification

Key areas to profile:
1. Distance computation loops (should be SIMD-bound)
2. Graph traversal (cache misses)
3. Memory allocation patterns
4. Quantization encoding/decoding

## Next Steps

1. ‚úÖ Run comprehensive benchmarks to establish baseline
2. üîÑ Profile hotspots using `perf`/`Instruments`
3. ‚è≥ Implement batch distance computation
4. ‚è≥ Convert remaining AoS to SoA layouts
5. ‚è≥ Add early termination optimizations
6. ‚è≥ Implement prefetching for graph traversal
